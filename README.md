*NOTE:* This file is a template that you can use to create the README for your project. The *TODO* comments below will highlight the information you should be sure to include.

# Azure ML Heart Failure Outcome Prediction Project

This project was intended to explore and prove conceptual and practical knowledge of the Azure ML Studio environment and specifically to train and deploy the best machine learning model possible into a full production environment. The approaches used were the Hyperdrive Parameter Tuning and AutoML features of Azure ML Studio. This project was written to be plug-and-play for anyone who wishes to run this in their own environment. To do so, simply replace the config file with your own from Azure ML Studio and run the cells in the order they are presented.

## Project Set Up and Installation
To run this project:
  - Create compute and compute cluster resources that match the names provided in the notebooks.
  - Replace the config file with a config file from your own Azure ML Studio subscription.
  - Upload the files to a notebook folder in the Notebooks section oof Azure ML Studio.
  - Run the notebooks from top to bottom.

## Dataset

### Overview
*TODO*: Explain about the data you are using and where you got it from.
The data that was obtained from kaggle and the raw csv file was pulled from the UCI Machine Learning Repository (Davide Chicco, Giuseppe Jurman: "Machine learning can predict survival of patients with heart failure from serum creatinine and ejection fraction alone". BMC Medical Informatics and Decision Making 20, 16 (2020)).

### Task
*TODO*: Explain the task you are going to be solving with this dataset and the features you will be using for it.

### Access
*TODO*: Explain how you are accessing the data in your workspace.

## Automated ML
*TODO*: Give an overview of the `automl` settings and configuration you used for this experiment

### Results
*TODO*: What are the results you got with your automated ML model? What were the parameters of the model? How could you have improved it?

*TODO* Remeber to provide screenshots of the `RunDetails` widget as well as a screenshot of the best model trained with it's parameters.

## Hyperparameter Tuning
*TODO*: What kind of model did you choose for this experiment and why? Give an overview of the types of parameters and their ranges used for the hyperparameter search


### Results
*TODO*: What are the results you got with your model? What were the parameters of the model? How could you have improved it?

*TODO* Remeber to provide screenshots of the `RunDetails` widget as well as a screenshot of the best model trained with it's parameters.

## Model Deployment
*TODO*: Give an overview of the deployed model and instructions on how to query the endpoint with a sample input.

## Screen Recording
*TODO* Provide a link to a screen recording of the project in action. Remember that the screencast should demonstrate:
- A working model
- Demo of the deployed  model
- Demo of a sample request sent to the endpoint and its response

## Standout Suggestions
*TODO (Optional):* This is where you can provide information about any standout suggestions that you have attempted.
